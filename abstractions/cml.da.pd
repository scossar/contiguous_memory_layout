#N canvas 1710 105 1647 1329 16;
#X obj 87 23 inlet bang;
#X obj 1158 678 t b s;
#X obj 1126 741 array get;
#X msg 1160 708 1;
#X obj 998 739 t b s;
#X obj 966 802 array get;
#X msg 1000 769 1;
#X obj 185 56 t f f;
#X obj 645 56 t f f;
#X obj 415 56 t f f;
#X obj 998 1166 array set;
#X obj 808 1099 cml.plus_equal;
#X obj 164 112 f;
#X obj 164 140 cml.range;
#X obj 394 256 f;
#X obj 624 396 f;
#X obj 394 284 cml.range;
#X obj 321 206 v \$0_i;
#X obj 559 350 v \$0_j;
#X obj 624 424 cml.range, f 14;
#X obj 661 490 v \$0_k;
#X obj 685 589 *, f 8;
#X obj 452 85 v \$0_p;
#X obj 746 556 v \$0_n;
#X obj 624 623 +, f 8;
#X obj 870 589 *, f 8;
#X obj 809 623 +, f 8;
#X obj 870 556 v \$0_k;
#X obj 931 556 v \$0_p;
#X obj 809 590 v \$0_j;
#X obj 917 1066 *, f 11;
#X obj 624 457 t b f;
#X obj 624 523 t b b b b b b, f 39;
#X text 697 622 // A_index;
#X text 878 619 // B_index;
#X obj 164 173 t b f, f 20;
#X obj 394 317 t b f, f 21;
#X obj 924 922 *, f 8;
#X obj 863 956 +, f 8;
#X obj 985 889 v \$0_p;
#X obj 863 923 v \$0_j;
#X obj 924 889 v \$0_i;
#X text 931 955 // C_index;
#X obj 808 850 t b b b b, f 21;
#X obj 87 56 t b b, f 10;
#X obj 87 1239 outlet done;
#X text 105 509 // multiplying flattened matrices A (m x n) B (n x p) \; for i in range(m) \; ....for j in range(p) \; ........sum = 0 \; ........for k in range(n) \; ............sum += A[i*n + k] * B[k*p + j] \; ........C[i*p + j] = sum \;;
#X obj 222 85 v \$0_n;
#X obj 682 85 v \$0_m;
#X obj 685 556 v \$0_k;
#X obj 624 590 v \$0_i;
#X text 106 477 // dA^[l-1] = W^[l]T.dZ^[l];
#X obj 998 23 inlet s_weights;
#X obj 1158 23 inlet s_dz;
#X obj 1458 23 inlet s_da_prev;
#X obj 185 23 inlet num_n_prev;
#X obj 415 23 inlet num_examples;
#X obj 645 23 inlet num_n;
#X text 106 667 // multiplying flattened matrices A.T . B \; for i in range (n) \\\\ cols of A \; ....for j in range(p) \\\\ cols of B \; ........sum = 0 \; ........for k in range(m) \\\\ cols of A.T (rows of A) \; ............// A.T[i \, k] = A[k \, i] = A[k*n + i] \; ............// B[k \, j] = B[k*p + j] \; ............sum += A[k*n + i] * B[k*n + j] \; ........C[i*n + j] = sum \; // NOTE: instead of accessing A[i*n + k] as in a regular matrix \, access A[k*n + i] to get the transposed element \;;
#X text 244 139 // for i in range(n_prev);
#X text 477 281 // for j in range(num_examples);
#X text 661 393 // for k in range(n);
#X text 107 895 // NOTE: as in all matrix multiplication abstractions \, I'm sticking with the use of the variables i \, j \, k \, n \, m \, p within the patch \, even though n and m have a different meaning in the context of a neural network.;
#X connect 0 0 44 0;
#X connect 1 0 3 0;
#X connect 1 1 2 2;
#X connect 2 0 30 1;
#X connect 3 0 2 1;
#X connect 4 0 6 0;
#X connect 4 1 5 2;
#X connect 5 0 30 0;
#X connect 6 0 5 1;
#X connect 7 0 12 1;
#X connect 7 1 47 0;
#X connect 8 0 15 1;
#X connect 8 1 48 0;
#X connect 9 0 14 1;
#X connect 9 1 22 0;
#X connect 11 0 10 0;
#X connect 12 0 13 0;
#X connect 13 0 35 0;
#X connect 14 0 16 0;
#X connect 15 0 19 0;
#X connect 16 0 36 0;
#X connect 19 0 31 0;
#X connect 19 1 43 0;
#X connect 21 0 24 1;
#X connect 23 0 21 1;
#X connect 24 0 5 0;
#X connect 25 0 26 1;
#X connect 26 0 2 0;
#X connect 27 0 25 0;
#X connect 28 0 25 1;
#X connect 29 0 26 0;
#X connect 30 0 11 1;
#X connect 31 0 32 0;
#X connect 31 1 20 0;
#X connect 32 0 50 0;
#X connect 32 1 49 0;
#X connect 32 2 23 0;
#X connect 32 3 29 0;
#X connect 32 4 27 0;
#X connect 32 5 28 0;
#X connect 35 0 14 0;
#X connect 35 1 17 0;
#X connect 36 0 15 0;
#X connect 36 1 18 0;
#X connect 37 0 38 1;
#X connect 38 0 10 1;
#X connect 39 0 37 1;
#X connect 40 0 38 0;
#X connect 41 0 37 0;
#X connect 43 0 11 0;
#X connect 43 1 40 0;
#X connect 43 2 41 0;
#X connect 43 3 39 0;
#X connect 44 0 45 0;
#X connect 44 1 12 0;
#X connect 49 0 21 0;
#X connect 50 0 24 0;
#X connect 52 0 4 0;
#X connect 53 0 1 0;
#X connect 54 0 10 2;
#X connect 55 0 7 0;
#X connect 56 0 9 0;
#X connect 57 0 8 0;
